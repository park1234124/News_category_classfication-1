import numpy as np
import matplotlib.pyplot as plt
from tensorflow.keras.models import *
from tensorflow.keras.layers import *

import tensorflow as tf

# gpus = tf.config.experimental.list_physical_devices('GPU')
# if gpus:
#   # Restrict TensorFlow to only allocate 1GB of memory on the first GPU
#   try:
#     tf.config.experimental.set_virtual_device_configuration(
#         gpus[0],
#         [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=128)])
#     logical_gpus = tf.config.experimental.list_logical_devices('GPU')
#     print(len(gpus), "Physical GPUs,", len(logical_gpus), "Logical GPUs")
#   except RuntimeError as e:
#     # Virtual devices must be set before GPUs have been initialized
#     print(e)

X_train, X_test, Y_train, Y_test = np.load(
    './crawling_data/news_data_max_29_wordsize_12740.npy',
    allow_pickle=True)
print(X_train.shape, Y_train.shape)
print(X_test.shape, Y_test.shape)

model = Sequential()
model.add(Embedding(12740, 300, input_length=29))
model.add(Conv1D(32, kernel_size=5, padding='same',
                 activation='relu'))
model.add(MaxPooling1D(pool_size=1))
model.add(LSTM(128, activation='tanh',
               return_sequences=True))
model.add(Dropout(0.3))
model.add(LSTM(64, activation='tanh',
               return_sequences=True))
model.add(Dropout(0.3))
model.add(LSTM(64, activation='tanh',
               return_sequences=True))
model.add(Dropout(0.3))
model.add(Flatten())
model.add(Dense(128, activation='relu'))
model.add(Dense(6, activation='softmax'))
model.summary()

model.compile(loss='categorical_crossentropy',
              optimizer='adam', metrics=['acc'])
fit_hist = model.fit(X_train, Y_train, batch_size=100,
    epochs=10, validation_data=(X_test, Y_test))
model.save('./output/news_category_classfication_model_{}.h5'.format(
    fit_hist.history['val_acc'][-1]))
plt.plot(fit_hist.history['acc'], label='accuracy')
plt.plot(fit_hist.history['val_acc'], label='val_accuracy')
plt.legend()
plt.show()